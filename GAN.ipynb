{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2 as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(tensor):\n",
    "    plt.figure(figsize=(1.25, 1.25))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(tensor.permute(1, 2, 0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 128, kernel_size=3, padding=1)\n",
    "        self.bnorm1 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bnorm2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bnorm3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 3, kernel_size=3, padding=1)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lrelu(self.conv1(x))\n",
    "        x = self.bnorm1(x)\n",
    "\n",
    "        x = self.lrelu(self.conv2(x))\n",
    "        x = self.bnorm2(x)\n",
    "\n",
    "        x = self.lrelu(self.conv3(x))\n",
    "        x = self.bnorm3(x)\n",
    "        \n",
    "        x = self.tanh(self.conv4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5)\n",
    "        self.bnorm1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 16, kernel_size=5)\n",
    "        self.bnorm2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16, 8, kernel_size=5)\n",
    "        self.bnorm3 = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(8, 4, kernel_size=5)\n",
    "        self.bnorm4 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(4, 2, kernel_size=5)\n",
    "        self.bnorm5 = nn.BatchNorm2d(2)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(2, 1, kernel_size=5)\n",
    "\n",
    "        self.fc = nn.Linear(64, 1)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lrelu(self.conv1(x))\n",
    "        x = self.bnorm1(x)\n",
    "\n",
    "        x = self.lrelu(self.conv2(x))\n",
    "        x = self.bnorm2(x)\n",
    "\n",
    "        x = self.lrelu(self.conv3(x))\n",
    "        x = self.bnorm3(x)\n",
    "\n",
    "        x = self.lrelu(self.conv4(x))\n",
    "        x = self.bnorm4(x)\n",
    "\n",
    "        x = self.lrelu(self.conv5(x))\n",
    "        x = self.bnorm5(x)\n",
    "\n",
    "        x = self.lrelu(self.conv6(x))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.sigm(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.tensor([0.49139968, 0.48215827 ,0.44653124])\n",
    "std = torch.tensor([0.24703233, 0.24348505, 0.26158768])\n",
    "transform = T.Compose([\n",
    "    T.ToImage(),\n",
    "    # T.Resize(size=(32, 32), antialias=True),\n",
    "    T.ToDtype(torch.float32, scale=True),\n",
    "    T.Normalize(mean=mean, std=std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform):\n",
    "        super().__init__()\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "train_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.9098384..2.1008148].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 125x125 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(train_data[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "gen_optim = optim.AdamW(params=generator.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "dis_optim = optim.AdamW(params=discriminator.parameters(), lr=5e-4, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m gen_loss \u001b[38;5;241m=\u001b[39m criterion(discriminator(gen_images), torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(images), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m     20\u001b[0m dis_loss \u001b[38;5;241m=\u001b[39m criterion(pred_cls, gt)\n\u001b[1;32m---> 22\u001b[0m avg_gen_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m gen_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     23\u001b[0m avg_dis_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dis_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     25\u001b[0m gen_optim\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "gen_losses = []\n",
    "dis_losses = []\n",
    "\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "\n",
    "num_epochs = 25\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    \n",
    "    avg_gen_loss = 0\n",
    "    avg_dis_loss = 0\n",
    "    for images, _ in train_loader:\n",
    "        images = images.to(device)\n",
    "        gen_images = generator(torch.randn((len(images), 3, 32, 32)).to(device))\n",
    "        pred_cls = discriminator(torch.cat((images, gen_images)).detach())\n",
    "        \n",
    "        gt = torch.cat((0.7 + (1.2 - 0.7) * torch.rand(len(images), 1), 0.0 + (0.3 - 0.0) * torch.rand(len(images), 1))).to(device)\n",
    "\n",
    "        gen_loss = criterion(discriminator(gen_images), torch.ones(len(images), 1).to(device))\n",
    "        dis_loss = criterion(pred_cls, gt)\n",
    "\n",
    "        avg_gen_loss += gen_loss.item()\n",
    "        avg_dis_loss += dis_loss.item()\n",
    "\n",
    "        gen_optim.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        gen_optim.step()\n",
    "\n",
    "        dis_optim.zero_grad()\n",
    "        dis_loss.backward()\n",
    "        dis_optim.step()\n",
    "    avg_gen_loss = avg_gen_loss / len(train_loader)\n",
    "    avg_dis_loss = avg_dis_loss / len(train_loader)\n",
    "\n",
    "    gen_losses.append(avg_gen_loss)\n",
    "    dis_losses.append(avg_dis_loss)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.title('Generator Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(which='both', axis='y')\n",
    "    plt.plot(gen_losses, linestyle='-', color='b', label='Generator')\n",
    "    plt.gca().set_ylim(bottom=0)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.title('Discriminator Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(which='both', axis='y')\n",
    "    plt.plot(dis_losses, linestyle='-', color='r', label='Discriminator')\n",
    "    plt.gca().set_ylim(bottom=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_image = torch.randn((1, 3, 32, 32)).to(device)\n",
    "    plot_image(test_image[0].cpu())\n",
    "    generated = (generator(test_image) + 1) / 2\n",
    "    plot_image(generated[0].cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
